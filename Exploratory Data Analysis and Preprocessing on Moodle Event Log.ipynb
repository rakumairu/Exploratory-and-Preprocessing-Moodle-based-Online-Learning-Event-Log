{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis and Preprocessing for Moodle's Event Log\n",
    "\n",
    "Moodle's Event Log is often used as dataset in research on Process Mining, but there are some problems that exist in the event log. Those problems are:\n",
    "1. Time Column didn't use a proper time format\n",
    "2. There's too many scenario which difficult to understand\n",
    "3. Sometimes there's still anomaly in the event log\n",
    "\n",
    "In this notebook we will do preprocessing and filtering on Moodle's event log on quiz taking to prepare it for Process Mining <br>\n",
    "\n",
    "Moodle's event log consist of 9 columns\n",
    "1. Time\n",
    "2. User full name\n",
    "3. Affected user\n",
    "4. Event context\n",
    "5. Component\n",
    "6. Event name\n",
    "7. Description\n",
    "8. Origin\n",
    "9. Ip address\n",
    "\n",
    "The preprocessing and filtering will consist of 7 main phases, convert time format, giving alias and filtering, count quiz attempt, join columns, drop columns, choose 3 main columns, and applying simple heuristic filtering\n",
    "\n",
    "![alt text](img/tahapan_jupyter.png \"Phase\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Preprocessing class and SimpleHeuristic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    \"\"\"Preprocessing Class\"\"\"\n",
    "    \n",
    "    def __init__(self, file):\n",
    "        \"\"\"Initialize class\"\"\"\n",
    "        \n",
    "        self.data = pd.read_csv(file)\n",
    "        \n",
    "    def getColumns(self):\n",
    "        \"\"\"Return list of columns in data\"\"\"\n",
    "        \n",
    "        return {'data': list(self.data.columns),'message': 'Succesfully fetch the data','status': 'success'}\n",
    "    \n",
    "    def getUniqueData(self):\n",
    "        \"\"\"Handle GET request to display data for giving alias\"\"\"\n",
    "        \n",
    "        # Initialize unique data array\n",
    "        # Store unique data in every column\n",
    "        unique_data = {}\n",
    "        \n",
    "        for col in self.data.columns:\n",
    "            # Get all unique values in a column\n",
    "            unique_data[col] = list(set(self.data[col]))\n",
    "        \n",
    "        # Return data to front end\n",
    "        return {\"data\":{\"column\": list(self.data.columns),\"data\": unique_data}}\n",
    "    \n",
    "    def convertTime(self, column):\n",
    "        \"\"\"Convert time format to ISO format\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Initialize array to store new formatted time\n",
    "            new_time =  []\n",
    "            \n",
    "            for idx, time in enumerate(self.data[column]):\n",
    "                new = datetime.strptime(time, '%d/%m/%y, %H:%M')\n",
    "                new_time.append(new)\n",
    "                \n",
    "            # Replace time\n",
    "            self.data[column] = new_time\n",
    "            \n",
    "            return 'Success'\n",
    "        \n",
    "        except Exception as e:\n",
    "            return e\n",
    "    \n",
    "    def alias(self, alias, column):\n",
    "        \"\"\"Handle POST request to map the alias data\"\"\"\n",
    "        \n",
    "        # Map value on spesific column\n",
    "        self.data[column] = self.data[column].map(alias)\n",
    "        \n",
    "        # Remove any missing value\n",
    "        self.data[column].replace('', np.nan, inplace=True)\n",
    "        self.data.dropna(subset=[column], inplace=True)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def countAttempt(self, base, count, start, end):\n",
    "        \"\"\"Count quiz attempted by every student\"\"\"\n",
    "        \n",
    "        # Get unique case id\n",
    "        id_list = self.data[base].unique()\n",
    "        \n",
    "        # Store data per case id\n",
    "        data_per_id = {}\n",
    "        for id in id_list:\n",
    "            if id not in data_per_id:\n",
    "                data_per_id[id] = self.data[self.data[base] == id]\n",
    "                \n",
    "        # Initialize new data\n",
    "        list_of_data = []\n",
    "        # Count every attempt\n",
    "        for key, data in data_per_id.items():\n",
    "            dt = data\n",
    "            time_id_list = []\n",
    "            id = np.nan\n",
    "            iter = 0\n",
    "            for x in range(len(dt.index)):\n",
    "                if dt[count].iloc[x] == start:\n",
    "                    iter+=1\n",
    "                    id = str(iter)\n",
    "                elif x != 0:\n",
    "                    if dt[count].iloc[x-1] == end:\n",
    "                        id = np.nan\n",
    "                time_id_list.append(id)\n",
    "            dt['n_attempt'] = time_id_list\n",
    "            dt.dropna(subset=['n_attempt'], inplace=True)\n",
    "            list_of_data.append(dt)\n",
    "            \n",
    "        # Concatenate all data\n",
    "        self.data = pd.concat(list_of_data)\n",
    "        # Sort the index\n",
    "        self.data.sort_index(inplace=True)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def joinColumn(self, column1, column2, columnName, delimiter):\n",
    "        \"\"\"Handle POST request to join two columns together\"\"\"\n",
    "        \n",
    "        if delimiter != None:\n",
    "            self.data[columnName] = self.data[column1].map(str) + str(delimiter) + self.data[column2].map(str)\n",
    "        else:\n",
    "            self.data[columnName] = self.data[column1].map(str) + self.data[column2].map(str)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def dropColumn(self, column):\n",
    "        \"\"\"Handle POST request to drop a column from data\"\"\"\n",
    "        \n",
    "        self.data.drop(column, axis=1, inplace=True)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def chooseColumn(self, case_id, event, timestamp):\n",
    "        \"\"\"Choose 3 main columns (case id, event, and timestamp)\"\"\"\n",
    "        \n",
    "        try:\n",
    "            # Arrange new input\n",
    "            new_input = [case_id, event, timestamp]\n",
    "            # Get columns from current data\n",
    "            old_columns = list(self.data.columns)\n",
    "            \n",
    "            # Initialize array to store new column\n",
    "            new_columns = []\n",
    "            # Prepare renamed columns\n",
    "            renamed_columns = ['case_id','event','timestamp']\n",
    "            \n",
    "            for val in new_input:\n",
    "                new_columns.append(old_columns[val])\n",
    "                \n",
    "            for idx, val in enumerate(old_columns):\n",
    "                for val2 in new_input:\n",
    "                    if idx != val2 and val not in new_columns:\n",
    "                        new_columns.append(val)\n",
    "                        renamed_columns.append(val)\n",
    "            \n",
    "            # Re-arrange column\n",
    "            self.data = self.data[new_columns]\n",
    "            # Rename columns\n",
    "            self.data.columns = renamed_columns\n",
    "            \n",
    "            return 'Success'\n",
    "        \n",
    "        except Exception as e:\n",
    "            return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Statistic:\n",
    "    \"\"\"Summary Statistic Class\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        if 'case_id' in data.columns and 'event' in data.columns and 'timestamp' in data.columns:\n",
    "            self.data = data\n",
    "        else:\n",
    "            raise Exception('Sorry your data is not ready yet')\n",
    "        \n",
    "    def summary(self):\n",
    "        \"\"\"Summary of the entire event log\"\"\"\n",
    "        \n",
    "        # Total number of case\n",
    "        total_case = len(self.data['case_id'].unique())\n",
    "        # Total number of event\n",
    "        total_event = len(self.data['event'])\n",
    "        # Total number of unique event\n",
    "        jenis_event = len(self.data['event'].unique())\n",
    "\n",
    "        # All unique event\n",
    "        all_event = list(set(self.data['event']))\n",
    "        # Calculate the occurance of every event\n",
    "        all_event_occurance = []\n",
    "        for event in all_event:\n",
    "            event_occurance = {}\n",
    "            occurance = len(self.data[self.data['event'] == event])\n",
    "            percentage = occurance / total_event\n",
    "            event_occurance['event'] = event\n",
    "            event_occurance['absolute'] = occurance\n",
    "            event_occurance['relative'] = percentage * 100\n",
    "            all_event_occurance.append(event_occurance)\n",
    "\n",
    "        # Sort all value\n",
    "        all_event_occurance.sort(key=self.absoluteColumn, reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'total_case': total_case,\n",
    "            'total_event': total_event,\n",
    "            'jenis_event': jenis_event,\n",
    "            'event_occurance': all_event_occurance\n",
    "        }\n",
    "    \n",
    "    def start(self):\n",
    "        \"\"\"Occurance of start event\"\"\"\n",
    "        \n",
    "        id_list = list(set(self.data['case_id']))\n",
    "        data_per_id = {}\n",
    "        for id in id_list:\n",
    "            if id not in data_per_id:\n",
    "                data_per_id[id] = self.data[self.data['case_id'] == id]\n",
    "        starts = []\n",
    "        for key, dt in data_per_id.items():\n",
    "            for x in range(len(dt.index)):\n",
    "                if x == 0:\n",
    "                    starts.append(dt['event'].iloc[x])\n",
    "                elif dt['case_id'].iloc[x-1] != dt['case_id'].iloc[x]:\n",
    "                    starts.append(dt['event'].iloc[x])\n",
    "        start_list = list(set(starts))\n",
    "\n",
    "        start_dict = {}\n",
    "        total_in_start = 0\n",
    "\n",
    "        for event in starts:\n",
    "            if event not in start_dict:\n",
    "                start_dict[event] = 1\n",
    "                total_in_start+=1\n",
    "            else:\n",
    "                start_dict[event]+=1\n",
    "                total_in_start+=1\n",
    "\n",
    "        # Dictionary occurance start and end event\n",
    "        start_occurance = []\n",
    "\n",
    "        for key, item in start_dict.items():\n",
    "            start = {}\n",
    "            occurance = item\n",
    "            percentage = occurance/total_in_start\n",
    "            start['event'] = key\n",
    "            start['absolute'] = occurance\n",
    "            start['relative'] = percentage * 100\n",
    "            start_occurance.append(start)\n",
    "\n",
    "        # Sort all value\n",
    "        start_occurance.sort(key=self.absoluteColumn, reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'start_event': start_list,\n",
    "            'start_occurance': start_occurance\n",
    "        }\n",
    "    \n",
    "    def end(self):\n",
    "        # List of all the case id\n",
    "        id_list = list(set(self.data['case_id']))\n",
    "        # Get data per id\n",
    "        data_per_id = {}\n",
    "        for id in id_list:\n",
    "            if id not in data_per_id:\n",
    "                data_per_id[id] = self.data[self.data['case_id'] == id]\n",
    "        # List start event and end event\n",
    "        ends = []\n",
    "        for key, dt in data_per_id.items():\n",
    "            for x in range(len(dt.index)):\n",
    "                if x == len(dt.index)-1:\n",
    "                    ends.append(dt['event'].iloc[x])\n",
    "                elif dt['case_id'].iloc[x+1] != dt['case_id'].iloc[x]:\n",
    "                    ends.append(dt['event'].iloc[x])\n",
    "        end_list = list(set(ends))\n",
    "\n",
    "        # Initialize dictionary to store end event\n",
    "        end_dict = {}\n",
    "        # Initialize sum of end event\n",
    "        total_in_end = 0\n",
    "\n",
    "        for event in ends:\n",
    "            if event not in end_dict:\n",
    "                end_dict[event] = 1\n",
    "                total_in_end+=1\n",
    "            else:\n",
    "                end_dict[event]+=1\n",
    "                total_in_end+=1\n",
    "\n",
    "        # Dictionary occurance start and end event\n",
    "        end_occurance = []\n",
    "\n",
    "        for key, item in end_dict.items():\n",
    "            end = {}\n",
    "            occurance = item\n",
    "            percentage = occurance/total_in_end\n",
    "            end['event'] = key\n",
    "            end['absolute'] = occurance\n",
    "            end['relative'] = percentage * 100\n",
    "            end_occurance.append(end)\n",
    "\n",
    "        # Sort all value\n",
    "        end_occurance.sort(key=self.absoluteColumn, reverse=True)\n",
    "        \n",
    "        return {\n",
    "            'end_event': end_list,\n",
    "            'end_occurance': end_occurance\n",
    "        }\n",
    "        \n",
    "    def absoluteColumn(self, value):\n",
    "        return value['absolute']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleHeuristic:\n",
    "    \"\"\"Simple Heuristic Filtering Class\"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        if 'case_id' in data.columns and 'event' in data.columns and 'timestamp' in data.columns:\n",
    "            self.data = data\n",
    "        else:\n",
    "            raise Exception('Sorry your data is not ready yet')\n",
    "    \n",
    "    def start(self):\n",
    "        # Kolom untuk sort data ulang\n",
    "        self.data['Sort'] = list([x for x in range(0,len(self.data['case_id']))])\n",
    "\n",
    "        # List dari semua id\n",
    "        id_list = self.data['case_id'].unique()\n",
    "\n",
    "        # Mengambil data per id\n",
    "        data_per_id = dict()\n",
    "        for id in id_list:\n",
    "            if id not in data_per_id:\n",
    "                data_per_id[id] = self.data[self.data['case_id'] == id]\n",
    "\n",
    "        # List of selected start event\n",
    "        list_of_data = []\n",
    "        for key, dt in data_per_id.items():\n",
    "            for ev in start:\n",
    "                if dt['event'].iloc[0] == ev:\n",
    "                    list_of_data.append(dt)\n",
    "\n",
    "        self.data = pd.concat(list_of_data)\n",
    "        self.data.sort_values('Sort', inplace=True)\n",
    "        self.data.drop('Sort', axis=1, inplace=True)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def end(self):\n",
    "        # Kolom untuk sort data ulang\n",
    "        self.data['Sort'] = list([x for x in range(0,len(self.data['case_id']))])\n",
    "\n",
    "        # List dari semua id\n",
    "        id_list = self.data['case_id'].unique()\n",
    "\n",
    "        # Mengambil data per id\n",
    "        data_per_id = dict()\n",
    "        for id in id_list:\n",
    "            if id not in data_per_id:\n",
    "                data_per_id[id] = self.data[self.data['case_id'] == id]\n",
    "\n",
    "        # List selected end event\n",
    "        list_of_data = []\n",
    "        for key, dt in data_per_id.items():\n",
    "            for ev in end:\n",
    "                if dt['event'].iloc[-1] == ev:\n",
    "                    list_of_data.append(dt)\n",
    "\n",
    "        self.data = pd.concat(list_of_data)\n",
    "        self.data.sort_values('Sort', inplace=True)\n",
    "        self.data.drop('Sort', axis=1, inplace=True)\n",
    "        \n",
    "        return 'Success'\n",
    "    \n",
    "    def all(self):\n",
    "        # Kolom untuk sort data ulang\n",
    "        self.data['Sort'] = list([x for x in range(0,len(self.data['case_id']))])\n",
    "\n",
    "        list_data = []\n",
    "        for idx, ev in enumerate(self.data['event']):\n",
    "            for evt in all:\n",
    "                if ev == evt:\n",
    "                    list_data.append(self.data.iloc[idx])\n",
    "\n",
    "        data = pd.DataFrame(list_data)\n",
    "        data.sort_values('Sort', inplace=True)\n",
    "        data.drop('Sort', axis=1, inplace=True)\n",
    "    \n",
    "        return 'Success'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = Preprocessing('logs_DS_20181002-1531_all_events.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert time format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2/10/18, 15:31\n",
       "1    2/10/18, 15:31\n",
       "2    2/10/18, 15:30\n",
       "3    2/10/18, 15:30\n",
       "4    2/10/18, 15:30\n",
       "Name: Time, dtype: object"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original format\n",
    "preprocessing.data['Time'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.convertTime('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2018-10-02 15:31:00\n",
       "1   2018-10-02 15:31:00\n",
       "2   2018-10-02 15:30:00\n",
       "3   2018-10-02 15:30:00\n",
       "4   2018-10-02 15:30:00\n",
       "Name: Time, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New format\n",
    "preprocessing.data['Time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Filtering on component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will only use quiz component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Logs',\n",
       " 'System',\n",
       " 'Quiz',\n",
       " 'Forum',\n",
       " 'URL',\n",
       " 'User report',\n",
       " 'Feedback',\n",
       " 'File',\n",
       " 'Overview report',\n",
       " 'Live logs',\n",
       " 'Statistics',\n",
       " 'Course participation',\n",
       " 'Activity report',\n",
       " 'User tours']"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Original value in component\n",
    "preprocessing.data['Component'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.alias({'Quiz':'Quiz'}, 'Component')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Quiz']"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# New value in component\n",
    "preprocessing.data['Component'].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtering on user full name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will change the value of user full name to number to hide their identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {}\n",
    "for idx, value in enumerate(preprocessing.data['User full name'].unique().tolist()):\n",
    "    maps[value] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.alias(maps, 'User full name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Give alias on event name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use Quiz attempt started, Course module viewed, Quiz attempt viewed, Quiz attempt submitted, Quiz attempt summary viewed, Quiz attempt abandoned, and Quiz attempt reviewed from Event name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = {\n",
    "    'Quiz attempt started' : 'qas',\n",
    "    'Course module viewed' : 'cmv',\n",
    "    'Quiz attempt viewed' : 'qav',\n",
    "    'Quiz attempt submitted' : 'qasub',\n",
    "    'Quiz attempt summary viewed' : 'qasv',\n",
    "    'Quiz attempt abandoned' : 'qaban',\n",
    "    'Quiz attempt reviewed ' : 'qar'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.alias(maps, 'Event name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Give alias and filtering on event context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use 1 quiz in this demo (Quiz: quiz 1 â€“ pengenalan dunia digital)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.alias({'Quiz: quiz 1 - pengenalan dunia digital':'q1'}, 'Event context')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Count quiz attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will count every quiz attempt that students do in Moodle<br>\n",
    "1. Base column is student that attempt the quiz\n",
    "2. Count column is column that represent the event\n",
    "3. Start column is event that represent the start of quiz attempt\n",
    "4. End column is event that represent the end of quiz attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = 'User full name'\n",
    "count = 'Event name'\n",
    "start = 'qas'\n",
    "end = 'qasub'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\demas\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "c:\\users\\demas\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.countAttempt(base, count, start, end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Join event name and event context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join event name and event context column so we can see which event corespond to which quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.joinColumn('Event context', 'Event name', 'event', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Join user full name and n_attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will join user full name with n_attempt and use it as case id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.joinColumn('User full name', 'n_attempt', 'case_id', '_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Drop affected user and Ip address"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we won't need affected user and ip address, we will drop the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.dropColumn('Affected user')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.dropColumn('IP address')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Choose 3 main columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need 3 main columns, which is case id, event, and timestamp<br>\n",
    "case id is in 9th position, event is in 9th position and Time is in 0th position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Success'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing.chooseColumn(9, 8, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic = Statistic(preprocessing.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Summary Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_case': 989,\n",
       " 'total_event': 3411,\n",
       " 'jenis_event': 6,\n",
       " 'event_occurance': [{'event': 'q1_cmv',\n",
       "   'absolute': 1519,\n",
       "   'relative': 44.532395192025795},\n",
       "  {'event': 'q1_qas', 'absolute': 989, 'relative': 28.994429785986515},\n",
       "  {'event': 'q1_qasub', 'absolute': 820, 'relative': 24.039871005570216},\n",
       "  {'event': 'q1_qav', 'absolute': 58, 'relative': 1.7003811199061858},\n",
       "  {'event': 'q1_qaban', 'absolute': 18, 'relative': 0.5277044854881267},\n",
       "  {'event': 'q1_qasv', 'absolute': 7, 'relative': 0.20521841102316035}]}"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start_event': ['q1_qas'],\n",
       " 'start_occurance': [{'event': 'q1_qas', 'absolute': 989, 'relative': 100.0}]}"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. End event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end_event': ['q1_cmv', 'q1_qasub', 'q1_qav'],\n",
       " 'end_occurance': [{'event': 'q1_qasub',\n",
       "   'absolute': 820,\n",
       "   'relative': 82.91203235591507},\n",
       "  {'event': 'q1_cmv', 'absolute': 151, 'relative': 15.267947421638016},\n",
       "  {'event': 'q1_qav', 'absolute': 18, 'relative': 1.820020222446916}]}"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "statistic.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Heuristic Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
